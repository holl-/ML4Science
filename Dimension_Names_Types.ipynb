{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Dimension Names and Types\n",
    "\n",
    "[![Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/tum-pbs/PhiML/blob/main/docs/Dimension_Names_Types.ipynb)\n",
    "&nbsp; ‚Ä¢ &nbsp; [üåê **Œ¶<sub>ML</sub>**](https://github.com/tum-pbs/PhiML)\n",
    "&nbsp; ‚Ä¢ &nbsp; [üìñ **Documentation**](https://tum-pbs.github.io/PhiML/)\n",
    "&nbsp; ‚Ä¢ &nbsp; [üîó **API**](https://tum-pbs.github.io/PhiML/phiml)\n",
    "&nbsp; ‚Ä¢ &nbsp; [**‚ñ∂ Videos**]()\n",
    "&nbsp; ‚Ä¢ &nbsp; [<img src=\"images/colab_logo_small.png\" height=4>](https://colab.research.google.com/github/tum-pbs/PhiML/blob/main/docs/Examples.ipynb) [**Examples**](https://tum-pbs.github.io/PhiML/Examples.html)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install phiml\n",
    "from phiml import math\n",
    "from phiml.math import spatial, instance, channel, batch\n",
    "import torch"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The interplay between dimension types and names enables user code to be much more concise and expressive.\n",
    "These advantages are hard to explain in abstract, so instead we are going to show the benefits on simple examples."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Gathering and Scattering\n",
    "\n",
    "Operations like `gather` and `scatter` -- taking values out of a tensor or putting data into a tensor -- are among the most basic and important operations.\n",
    "Let's consider the following task: We want to compute `min(0, value)` for some values at given `indices` of a `data` tensor and write the updated values back to the tensor.\n",
    "\n",
    "Let's look at the Œ¶-ML version first. We are given the `data`, ordered in the usual format y,x and `indices` ordered as x,y."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "data = math.tensor([[1, 2, 3], [-4, -5, -6]], spatial('y,x'))\n",
    "indices = math.tensor([(0, 0), (2, 1)], instance('indices'), channel(idx='x,y'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can compute the result by gathering the values at the indices, computing the `minimum`, and then writing them back."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "0; 2; 3; -4; -5; -6 \u001B[92m(yÀ¢=2, xÀ¢=3)\u001B[0m"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.scatter(data, indices, math.minimum(0, data[indices]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "As expected, the 1 at index (0,0) was replaced by a 0 while the -6 at (2,1) was already lower than 0.\n",
    "Also, the channel order was automatically matched to the dimension order since Œ¶-ML allows us to specify it directly.\n",
    "\n",
    "Actually, the Œ¶-ML scatter function already has a mode for computing the minimum, so we could have instead written"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "0; 2; 3; -4; -5; -6 \u001B[92m(yÀ¢=2, xÀ¢=3)\u001B[0m"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.scatter(data, indices, 0, mode=min)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now let's look at the same operation in PyTorch, without dimension names."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "data = torch.tensor([[1, 2, 3], [-4, -5, -6]])  # y,x\n",
    "indices = torch.tensor([(0, 0), (2, 1)])  # x,y"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "It turns out that doing this is quite hard to get right.\n",
    "The following is what ChatGPT came up with, given a detailed description of the task:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index 2 is out of bounds for dimension 0 with size 2\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # ChatGPT \"solution\"\n",
    "    update_indices = indices[:, [1, 0]]\n",
    "    update_values = torch.min(torch.zeros_like(update_indices, dtype=data.dtype), data[update_indices[:, 0], update_indices[:, 1]])\n",
    "    data.scatter_add_(0, update_indices, update_values)\n",
    "except RuntimeError as err:\n",
    "    print(err)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "ChatGPT is unable to correct this mistake, even when given the error message.\n",
    "With PyTorch, it's also not possible to gather using to `[]` syntax in this situation."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index 2 is out of bounds for dimension 0 with size 2\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    data[indices[:, [1, 0]]]\n",
    "except IndexError as err:\n",
    "    print(err)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Getting this simple exercise right is quite difficult for someone not intimately familiar with PyTorch. We will leave this as an exercise to the reader.\n",
    "\n",
    "Now imagine, we had a batch dimension on `data` as well!\n",
    "Let's try this in Œ¶-ML."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "data = math.tensor([[1, 2, 3], [-4, -5, -6]], spatial('y,x'))\n",
    "indices = math.tensor([(0, 0), (2, 1)], instance('indices'), channel(idx='x,y'))\n",
    "data *= math.range(batch(b=10))  # this is new!"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Our code from above works with this setting as well. To check this, we print batch index 1, which matches the case above."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "0; 2; 3; -4; -5; -6 \u001B[92m(yÀ¢=2, xÀ¢=3)\u001B[0m"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.scatter(data, indices, 0, mode=min).b[1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Adapting the PyTorch code requires detailed knowledge of the behavior of the respective gather and scatter operations.\n",
    "You are welcome to try it!\n",
    "\n",
    "Unsurprisingly, the same behavior can be observed when considering batched indices instead of batched values."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Laplace Operator\n",
    "\n",
    "Consider the discrete laplace operator ‚àá¬≤. On a 1D grid, it can be computed with the stencil (1, -2, 1) and in 2D with the stencil (0 1 0 / 1 -4, 1 / 0 1 0).\n",
    "With Œ¶-ML's typed dimensions, we can implement this"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[94m(1, -2, 1)\u001B[0m along \u001B[92mxÀ¢\u001B[0m\n",
      "\u001B[94m  0,  1,  0,\n",
      "  1, -4,  1,\n",
      "  0,  1,  0\u001B[0m  along \u001B[92m(yÀ¢=3, xÀ¢=3)\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "data_1d = math.tensor([0, 1, 0], spatial('x'))\n",
    "data_2d = math.tensor([[0, 0, 0], [0, 1, 0], [0, 0, 0]], spatial('y,x'))\n",
    "\n",
    "def laplace(x, padding='zero-gradient'):\n",
    "    left, center, right = math.shift(x, (-1, 0, 1), spatial, padding)\n",
    "    return math.sum((left + right - 2 * center), 'shift')\n",
    "\n",
    "print(laplace(data_1d))\n",
    "math.print(laplace(data_2d))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "This automatically generalizes to *n* dimensions since we shift in all *spatial* dimensions.\n",
    "\n",
    "Doing this directly with PyTorch is much more cumbersome.\n",
    "After multiple iterations of generating code with ChatGPT and feeding it back the error message, it converged on the following output:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given groups=1, weight of size [1, 3, 3], expected input[1, 1, 5] to have 3 channels, but got 1 channels instead\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# ChatGPT \"solution\"\n",
    "def laplace_operator_nd(grid):\n",
    "    # Get the number of dimensions\n",
    "    ndim = grid.dim()\n",
    "\n",
    "    # Construct the Laplace stencil for n-dimensions\n",
    "    laplace_stencil = torch.zeros((1,) * (ndim - 1) + (1, 3, 3))\n",
    "    center_idx = tuple(slice(1, 2) for _ in range(ndim - 1)) + (0, 1, 1)\n",
    "    laplace_stencil[center_idx] = -2\n",
    "    for i in range(ndim - 1):\n",
    "        laplace_stencil = laplace_stencil.narrow(i, 0, 1).clone()\n",
    "\n",
    "    # Apply the convolution along each dimension\n",
    "    laplace_result = grid.clone()\n",
    "    for i in range(ndim):\n",
    "        laplace_result = F.conv1d(laplace_result.unsqueeze(0), laplace_stencil.to(laplace_result.device), padding=1)\n",
    "        laplace_result = laplace_result.squeeze(0)\n",
    "\n",
    "    return laplace_result\n",
    "\n",
    "\n",
    "data_1d = torch.tensor([1, 2, 3, 4, 5])\n",
    "try:\n",
    "    result_1d = laplace_operator_nd(data_1d)\n",
    "except RuntimeError as err:\n",
    "    print(err)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The n-dimensional laplace seems to be too difficult for current LLMs to handle with PyTorch, indicating that the API is not well-suited to the task.\n",
    "However, ChatGPT is able to generate versions for a fixed number of dimensions.\n",
    "\n",
    "The below output does work for inputs of type float, but an additional cast is required to make it work with our example.\n",
    "These data type problems are always resolved under-the-hood in Œ¶-ML. Our version even accepts `bool` and `complex` inputs, neither of which work with PyTorch out-of-the-box."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expected scalar type Long but found Float\n"
     ]
    }
   ],
   "source": [
    "# ChatGPT solution for 1D laplace\n",
    "def laplace_operator_1d(grid):\n",
    "    laplace_stencil = torch.Tensor([1, -2, 1]).view(1, 1, -1)\n",
    "    laplace_result = F.conv1d(grid.view(1, 1, -1), laplace_stencil, padding=1)\n",
    "    return laplace_result.view(-1)\n",
    "\n",
    "# Example usage:\n",
    "grid_1d = torch.tensor([0, 1, 0])\n",
    "try:\n",
    "    result_1d = laplace_operator_1d(grid_1d)\n",
    "except RuntimeError as err:\n",
    "    print(err)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Further Reading\n",
    "\n",
    "Dimension names and types are organized in the [shapes of tensors](Shapes.html).\n",
    "\n",
    "Also see the [introduction to tensors](Tensors.html).\n",
    "\n",
    "[üåê **Œ¶<sub>ML</sub>**](https://github.com/tum-pbs/PhiML)\n",
    "&nbsp; ‚Ä¢ &nbsp; [üìñ **Documentation**](https://tum-pbs.github.io/PhiML/)\n",
    "&nbsp; ‚Ä¢ &nbsp; [üîó **API**](https://tum-pbs.github.io/PhiML/phiml)\n",
    "&nbsp; ‚Ä¢ &nbsp; [**‚ñ∂ Videos**]()\n",
    "&nbsp; ‚Ä¢ &nbsp; [<img src=\"images/colab_logo_small.png\" height=4>](https://colab.research.google.com/github/tum-pbs/PhiML/blob/main/docs/Examples.ipynb) [**Examples**](https://tum-pbs.github.io/PhiML/Examples.html)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}