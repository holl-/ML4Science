{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# ML4Science Quickstart\n",
    "\n",
    "[![Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/holl-/ML4Science/blob/main/docs/Introduction.ipynb) \n",
    "&nbsp; ‚Ä¢ &nbsp; [üåê **ML4Science**](https://github.com/holl-/ML4Science)\n",
    "&nbsp; ‚Ä¢ &nbsp; [üìñ **Documentation**](https://holl-.github.io/ML4Science/)\n",
    "&nbsp; ‚Ä¢ &nbsp; [üîó **API**](https://holl-.github.io/ML4Science/ml4s)\n",
    "&nbsp; ‚Ä¢ &nbsp; [**‚ñ∂ Videos**]()\n",
    "&nbsp; ‚Ä¢ &nbsp; [<img src=\"images/colab_logo_small.png\" height=4>](https://colab.research.google.com/github/holl-/ML4Science/blob/main/docs/Examples.ipynb) [**Examples**](https://holl-.github.io/ML4Science/Examples.html)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Installation\n",
    "\n",
    "Install ML4Science with [pip](https://pypi.org/project/pip/) on [Python 3.6](https://www.python.org/downloads/) and later:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install ml4s"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Install [PyTorch](https://pytorch.org/), [TensorFlow](https://www.tensorflow.org/install) or [Jax](https://github.com/google/jax#installation) to enable machine learning capabilities and GPU execution.\n",
    "See the [detailed installation instructions](https://holl-.github.io/ML4Science/Installation_Instructions.html)."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from ml4s import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Usage without ML4Science's Tensors\n",
    "\n",
    "You can call many functions on native tensors directly.\n",
    "ML4Science will dispatch the call to the corresponding library and return the result as another native tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0.841471"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.sin(1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "DeviceArray([0.841471], dtype=float32)"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from jax import numpy as jnp\n",
    "math.sin(jnp.asarray([1.]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([0.8415], device='cuda:0')"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "math.sin(torch.tensor([1.]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.84147096], dtype=float32)>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "math.sin(tf.constant([1.]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array([0.841471], dtype=float32)"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "math.sin(np.asarray([1.]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## ML4Science's `Tensor`\n",
    "\n",
    "For more advanced operations, we recommend using [ML4Science's tensors](Tensors.html).\n",
    "While ML4Science includes a [unified low-level API](https://holl-.github.io/ML4Science/ml4s/backend/#ml4s.backend.Backend) that behaves much like NumPy, using it correctly (so that the code is actually compatible with all libraries) is difficult.\n",
    "Instead, ML4Science provides a higher-level API consisting of the [`Tensor` class](https://holl-.github.io/ML4Science/ml4s/math/#ml4s.math.Tensor), the [`math`](https://holl-.github.io/ML4Science/ml4s/math) functions and other odds and ends, that makes writing unified code easy.\n",
    "Tensors can be created by wrapping an existing backend-specific tensor or array:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "\u001B[94m(1, 2, 3)\u001B[0m \u001B[93mint64\u001B[0m"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_tensor = torch.tensor([1, 2, 3])\n",
    "math.tensor(torch_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "\u001B[94m(1, 2, 3)\u001B[0m \u001B[93mint64\u001B[0m"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.wrap(torch_tensor)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The difference between `tensor` and `wrap` is that `wrap` keeps the original data you pass in while `tensor` will convert the data to the default backend which can be set using [`math.use()`](https://holl-.github.io/ML4Science/ml4s/math/#ml4s.math.use)."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "torch"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.use('jax')\n",
    "math.wrap(torch_tensor).default_backend"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "jax"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.tensor(torch_tensor).default_backend"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The last `tensor` call converted the PyTorch tensor to a Jax `DeviceArray` using a no-copy routine from [`dlpack`](https://github.com/dmlc/dlpack) under the hood."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dimension Types\n",
    "\n",
    "For tensors with more than one dimensions, you have to specify a name and type for each.\n",
    "Possible types are *batch* for parallelizing code, *channel* for listing features (color channels or x/y/z components) and *spatial* for equally-spaced sample points (width/height of an image, 1D time series, etc.).\n",
    "For an exhaustive list, see [here](Shapes.html)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "\u001B[94m(1, 2, 3)\u001B[0m; \u001B[94m(4, 5, 6)\u001B[0m \u001B[92m(dim1·µá=2, dim2·∂ú=3)\u001B[0m \u001B[93mint64\u001B[0m"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ml4s.math import batch, spatial, channel\n",
    "torch_tensor = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "math.wrap(torch_tensor, batch('dim1'), channel('dim2'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The superscript `b` and `c` denote the dimension type.\n",
    "When creating a new tensor from scratch, we also need to specify the size along each dimension:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "\u001B[94m(0.072, 0.020, 0.077)\u001B[0m; \u001B[94m(0.879, 0.165, 0.102)\u001B[0m \u001B[92m(dim1·µá=2, dim2·∂ú=3)\u001B[0m"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.random_uniform(batch(dim1=2), channel(dim2=3))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "When passing tensors to a neural network, the tensors are transposed to match the preferred dimension order (`BHWC` for TensorFlow/Jax, `BCHW` for PyTorch).\n",
    "For example, we can pass any number of batch and channel dimensions to an MLP."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "\u001B[92m(b1·µá=4, b2·µá=10, vector·∂ú=3)\u001B[0m \u001B[94m-1.04e-04 ¬± 3.0e-01\u001B[0m \u001B[37m(-1e+00...9e-01)\u001B[0m"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ml4s import nn\n",
    "mlp = nn.mlp(in_channels=6, out_channels=3, layers=[64, 64])\n",
    "data = math.random_normal(batch(b1=4, b2=10), channel(c1=2, c2=3))\n",
    "math.native_call(mlp, data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The network here is a standard fully-connected network module with two hidden layers of 64 neurons each.\n",
    "The native tensor that is passed to the network has shape (40, 6) as all batch dimensions are compressed into the first and all channel dimensions into the last dimension.\n",
    "\n",
    "For a network acting on spatial data, we would add *spatial* dimensions."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "\u001B[92m(b1·µá=4, b2·µá=10, xÀ¢=28, yÀ¢=28, vector·∂ú=3)\u001B[0m \u001B[94m-0.004 ¬± 0.322\u001B[0m \u001B[37m(-2e+00...2e+00)\u001B[0m"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = nn.u_net(in_channels=6, out_channels=3, in_spatial=2)\n",
    "data = math.random_normal(batch(b1=4, b2=10), channel(c1=2, c2=3), spatial(x=28, y=28))\n",
    "math.native_call(mlp, data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In this example, we ran a 2D [U-Net](https://en.wikipedia.org/wiki/U-Net#:~:text=U%2DNet%20is%20a%20convolutional,of%20the%20University%20of%20Freiburg.).\n",
    "For a 1D or 3D variant, we would pass `in_spatial=1` or `3`, respectively, and add the corresponding number of spatial dimensions to `data`."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Slicing\n",
    "\n",
    "Slicing in ML4Science is done by dimension names.\n",
    "Say we have a set of images:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "\u001B[92m(set·µá=4, xÀ¢=28, yÀ¢=28, channels·∂ú=3)\u001B[0m \u001B[94m0.502 ¬± 0.288\u001B[0m \u001B[37m(1e-04...1e+00)\u001B[0m"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images = math.random_uniform(batch(set=4), spatial(x=28, y=28), channel(channels=3))\n",
    "images"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The red, green and blue components are stored inside the `channels` dimension.\n",
    "Then to get just the red component of the last entry in the set, we can write"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "\u001B[92m(xÀ¢=28, yÀ¢=28)\u001B[0m \u001B[94m0.501 ¬± 0.291\u001B[0m \u001B[37m(2e-03...1e+00)\u001B[0m"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.set[-1].channels[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Or we can slice using a dictionary"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "\u001B[92m(xÀ¢=28, yÀ¢=28)\u001B[0m \u001B[94m0.501 ¬± 0.291\u001B[0m \u001B[37m(2e-03...1e+00)\u001B[0m"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images[{'set': -1, 'channels': 0}]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Slicing the NumPy way, i.e. `images[-1, :, :, 0]` is not supported because the order of dimensions generally depends on which backend you use.\n",
    "\n",
    "To make your code easier to read, you may name slices along dimensions as well.\n",
    "In the above example, we might name the red, green and blue channels explicitly:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "\u001B[92m(xÀ¢=28, yÀ¢=28)\u001B[0m \u001B[94m0.500 ¬± 0.276\u001B[0m \u001B[37m(2e-03...1e+00)\u001B[0m"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images = math.random_uniform(batch(set=4), spatial(x=28, y=28), channel(channels='red,green,blue'))\n",
    "images.set[-1].channels['red']\n",
    "images[{'set': -1, 'channels': 'red'}]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "To select multiple items by index, use the syntax `tensor.<dim>[start:end:step]` where `start >= 0`, `end` and `step > 0` are integers."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "\u001B[92m(set·µá=4, xÀ¢=2, yÀ¢=28, channels·∂ú=red,green,blue)\u001B[0m \u001B[94m0.509 ¬± 0.282\u001B[0m \u001B[37m(4e-03...1e+00)\u001B[0m"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.x[1:3]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "To select multiple named slices, pass a tuple, list, or comma-separated string."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "\u001B[92m(set·µá=4, xÀ¢=28, yÀ¢=28, channels·∂ú=red,blue)\u001B[0m \u001B[94m0.503 ¬± 0.288\u001B[0m \u001B[37m(2e-04...1e+00)\u001B[0m"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.channels['red,blue']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "You can iterate along a dimension or unstack a tensor along a dimension."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[94m0.5032147\u001B[0m\n",
      "\u001B[94m0.50452465\u001B[0m\n",
      "\u001B[94m0.49833444\u001B[0m\n",
      "\u001B[94m0.5087652\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "for image in images.set:\n",
    "    print(math.mean(image))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "[\u001B[92m(xÀ¢=28, yÀ¢=28, channels·∂ú=red,green,blue)\u001B[0m \u001B[94m0.503 ¬± 0.292\u001B[0m \u001B[37m(4e-04...1e+00)\u001B[0m,\n \u001B[92m(xÀ¢=28, yÀ¢=28, channels·∂ú=red,green,blue)\u001B[0m \u001B[94m0.505 ¬± 0.287\u001B[0m \u001B[37m(6e-04...1e+00)\u001B[0m,\n \u001B[92m(xÀ¢=28, yÀ¢=28, channels·∂ú=red,green,blue)\u001B[0m \u001B[94m0.498 ¬± 0.290\u001B[0m \u001B[37m(1e-04...1e+00)\u001B[0m,\n \u001B[92m(xÀ¢=28, yÀ¢=28, channels·∂ú=red,green,blue)\u001B[0m \u001B[94m0.509 ¬± 0.284\u001B[0m \u001B[37m(2e-04...1e+00)\u001B[0m]"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(images.set)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "You can even convert named slices to a `dict` or use them as keyword arguments."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "data": {
      "text/plain": "{0: \u001B[92m(xÀ¢=28, yÀ¢=28, channels·∂ú=red,green,blue)\u001B[0m \u001B[94m0.503 ¬± 0.292\u001B[0m \u001B[37m(4e-04...1e+00)\u001B[0m,\n 1: \u001B[92m(xÀ¢=28, yÀ¢=28, channels·∂ú=red,green,blue)\u001B[0m \u001B[94m0.505 ¬± 0.287\u001B[0m \u001B[37m(6e-04...1e+00)\u001B[0m,\n 2: \u001B[92m(xÀ¢=28, yÀ¢=28, channels·∂ú=red,green,blue)\u001B[0m \u001B[94m0.498 ¬± 0.290\u001B[0m \u001B[37m(1e-04...1e+00)\u001B[0m,\n 3: \u001B[92m(xÀ¢=28, yÀ¢=28, channels·∂ú=red,green,blue)\u001B[0m \u001B[94m0.509 ¬± 0.284\u001B[0m \u001B[37m(2e-04...1e+00)\u001B[0m}"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(images.set)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Red: \u001B[94m(0.485, 0.500, 0.503, 0.500)\u001B[0m along \u001B[92mset·µá\u001B[0m, Green: \u001B[94m(0.500, 0.507, 0.503, 0.511)\u001B[0m along \u001B[92mset·µá\u001B[0m, Blue: \u001B[94m(0.525, 0.507, 0.489, 0.515)\u001B[0m along \u001B[92mset·µá\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "def color_transform(red, green, blue):\n",
    "    print(f\"Red: {math.mean(red)}, Green: {math.mean(green)}, Blue: {math.mean(blue)}\")\n",
    "\n",
    "color_transform(**dict(images.channels))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Further Reading\n",
    "\n",
    "Learn more about the [dimension types](Shapes.html) and how to efficiently [operate on tensors](Tensors.html).\n",
    "\n",
    "ML4Science unifies [data types](Data_Types.html) as well and lets you set the floating point precision globally or by context.\n",
    "\n",
    "While the dimensionality of neural networks must be specified during network creation, this is not the case for math functions.\n",
    "These [automatically adapt to the number of spatial dimensions of the data that is passed in](N_Dimensional.html).\n",
    "\n",
    "[üåê **ML4Science**](https://github.com/holl-/ML4Science)\n",
    "&nbsp; ‚Ä¢ &nbsp; [üìñ **Documentation**](https://holl-.github.io/ML4Science/)\n",
    "&nbsp; ‚Ä¢ &nbsp; [üîó **API**](https://holl-.github.io/ML4Science/ml4s)\n",
    "&nbsp; ‚Ä¢ &nbsp; [**‚ñ∂ Videos**]()\n",
    "&nbsp; ‚Ä¢ &nbsp; [<img src=\"images/colab_logo_small.png\" height=4>](https://colab.research.google.com/github/holl-/ML4Science/blob/main/docs/Examples.ipynb) [**Examples**](https://holl-.github.io/ML4Science/Examples.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}