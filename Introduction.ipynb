{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# UnifyML Quickstart\n",
    "\n",
    "[![Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/holl-/UnifyML/blob/main/docs/Introduction.ipynb) \n",
    "&nbsp; ‚Ä¢ &nbsp; [üåê **UnifyML**](https://github.com/holl-/UnifyML)\n",
    "&nbsp; ‚Ä¢ &nbsp; [üìñ **Documentation**](https://holl-.github.io/UnifyML/)\n",
    "&nbsp; ‚Ä¢ &nbsp; [üîó **API**](https://holl-.github.io/UnifyML/unifyml)\n",
    "&nbsp; ‚Ä¢ &nbsp; [**‚ñ∂ Videos**]()\n",
    "&nbsp; ‚Ä¢ &nbsp; [<img src=\"images/colab_logo_small.png\" height=4>](https://colab.research.google.com/github/holl-/UnifyML/blob/main/docs/Examples.ipynb) [**Examples**](https://holl-.github.io/UnifyML/Examples.html)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Installation\n",
    "\n",
    "Install UnifyML with [pip](https://pypi.org/project/pip/) on [Python 3.6](https://www.python.org/downloads/) and later:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# !pip install unifyml"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Install [PyTorch](https://pytorch.org/), [TensorFlow](https://www.tensorflow.org/install) or [Jax](https://github.com/google/jax#installation) to enable machine learning capabilities and GPU execution.\n",
    "See the [detailed installation instructions](https://holl-.github.io/UnifyML/Installation_Instructions.html)."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from unifyml import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Usage without UnifyML's Tensors\n",
    "\n",
    "You can call many functions on native tensors directly.\n",
    "UnifyML will dispatch the call to the corresponding library and return the result as another native tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0.841471"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.sin(1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "DeviceArray([0.841471], dtype=float32)"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from jax import numpy as jnp\n",
    "math.sin(jnp.asarray([1.]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([0.8415], device='cuda:0')"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "math.sin(torch.tensor([1.]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.84147096], dtype=float32)>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "math.sin(tf.constant([1.]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array([0.841471], dtype=float32)"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "math.sin(np.asarray([1.]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## UnifyML's `Tensor`\n",
    "\n",
    "For more advanced operations, we recommend using [UnifyML's tensors](Tensors.html).\n",
    "While UnifyML includes a [unified low-level API](https://holl-.github.io/UnifyML/unifyml/backend/#unifyml.backend.Backend) that behaves much like NumPy, using it correctly (so that the code is actually compatible with all libraries) is difficult.\n",
    "Instead, UnifyML provides a higher-level API consisting of the [`Tensor` class](https://holl-.github.io/UnifyML/unifyml/math/#unifyml.math.Tensor), the [`math`](https://holl-.github.io/UnifyML/unifyml/math) functions and other odds and ends, that makes writing unified code easy.\n",
    "Tensors can be created by wrapping an existing backend-specific tensor or array:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "\u001B[94m(1, 2, 3)\u001B[0m \u001B[93mint64\u001B[0m"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_tensor = torch.tensor([1, 2, 3])\n",
    "math.tensor(torch_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "\u001B[94m(1, 2, 3)\u001B[0m \u001B[93mint64\u001B[0m"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.wrap(torch_tensor)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The difference between `tensor` and `wrap` is that `wrap` keeps the original data you pass in while `tensor` will convert the data to the default backend which can be set using [`math.use()`](https://holl-.github.io/UnifyML/unifyml/math/#unifyml.math.use)."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "torch"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.use('jax')\n",
    "math.wrap(torch_tensor).default_backend"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "jax"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.tensor(torch_tensor).default_backend"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The last `tensor` call converted the PyTorch tensor to a Jax `DeviceArray` using a no-copy routine from [`dlpack`](https://github.com/dmlc/dlpack) under the hood."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dimension Types\n",
    "\n",
    "For tensors with more than one dimensions, you have to specify a name and type for each.\n",
    "Possible types are *batch* for parallelizing code, *channel* for listing features (color channels or x/y/z components) and *spatial* for equally-spaced sample points (width/height of an image, 1D time series, etc.).\n",
    "For an exhaustive list, see [here](Shapes.html)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "\u001B[94m(1, 2, 3)\u001B[0m; \u001B[94m(4, 5, 6)\u001B[0m \u001B[92m(dim1·µá=2, dim2·∂ú=3)\u001B[0m \u001B[93mint64\u001B[0m"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from unifyml.math import batch, spatial, channel\n",
    "torch_tensor = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "math.wrap(torch_tensor, batch('dim1'), channel('dim2'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The superscript `b` and `c` denote the dimension type.\n",
    "When creating a new tensor from scratch, we also need to specify the size along each dimension:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "\u001B[94m(0.072, 0.020, 0.077)\u001B[0m; \u001B[94m(0.879, 0.165, 0.102)\u001B[0m \u001B[92m(dim1·µá=2, dim2·∂ú=3)\u001B[0m"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.random_uniform(batch(dim1=2), channel(dim2=3))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "When passing tensors to a neural network, the tensors are transposed to match the preferred dimension order (`BHWC` for TensorFlow/Jax, `BCHW` for PyTorch).\n",
    "For example, we can pass any number of batch and channel dimensions to an MLP."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "\u001B[92m(b1·µá=4, b2·µá=10, vector·∂ú=3)\u001B[0m \u001B[94m-1.04e-04 ¬± 3.0e-01\u001B[0m \u001B[37m(-1e+00...9e-01)\u001B[0m"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from unifyml import nn\n",
    "mlp = nn.mlp(in_channels=6, out_channels=3, layers=[64, 64])\n",
    "data = math.random_normal(batch(b1=4, b2=10), channel(c1=2, c2=3))\n",
    "math.native_call(mlp, data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The network here is a standard fully-connected network module with two hidden layers of 64 neurons each.\n",
    "The native tensor that is passed to the network has shape (40, 6) as all batch dimensions are compressed into the first and all channel dimensions into the last dimension.\n",
    "\n",
    "For a network acting on spatial data, we would add *spatial* dimensions."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "\u001B[92m(b1·µá=4, b2·µá=10, xÀ¢=28, yÀ¢=28, vector·∂ú=3)\u001B[0m \u001B[94m-0.004 ¬± 0.322\u001B[0m \u001B[37m(-2e+00...2e+00)\u001B[0m"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = nn.u_net(in_channels=6, out_channels=3, in_spatial=2)\n",
    "data = math.random_normal(batch(b1=4, b2=10), channel(c1=2, c2=3), spatial(x=28, y=28))\n",
    "math.native_call(mlp, data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In this example, we ran a 2D [U-Net](https://en.wikipedia.org/wiki/U-Net#:~:text=U%2DNet%20is%20a%20convolutional,of%20the%20University%20of%20Freiburg.).\n",
    "For a 1D or 3D variant, we would pass `in_spatial=1` or `3`, respectively, and add the corresponding number of spatial dimensions to `data`."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Slicing\n",
    "\n",
    "Slicing in UnifyML is done by dimension names.\n",
    "Say we have a set of images:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "\u001B[92m(set·µá=4, xÀ¢=28, yÀ¢=28, channels·∂ú=3)\u001B[0m \u001B[94m0.504 ¬± 0.287\u001B[0m \u001B[37m(8e-05...1e+00)\u001B[0m"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images = math.random_uniform(batch(set=4), spatial(x=28, y=28), channel(channels=3))\n",
    "images"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The red, green and blue components are stored inside the `channels` dimension.\n",
    "Then to get just the red component of the last entry in the set, we can write"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "\u001B[92m(xÀ¢=28, yÀ¢=28)\u001B[0m \u001B[94m0.523 ¬± 0.284\u001B[0m \u001B[37m(1e-03...1e+00)\u001B[0m"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.set[-1].channels[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Or we can slice using a dictionary"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "\u001B[92m(xÀ¢=28, yÀ¢=28)\u001B[0m \u001B[94m0.523 ¬± 0.284\u001B[0m \u001B[37m(1e-03...1e+00)\u001B[0m"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images[{'set': -1, 'channels': 0}]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Slicing the NumPy way, i.e. `images[-1, :, :, 0]` is not supported because the order of dimensions generally depends on which backend you use.\n",
    "\n",
    "To make your code easier to read, you may name slices along dimensions as well.\n",
    "In the above example, we might name the red, green and blue channels explicitly:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "data": {
      "text/plain": "\u001B[92m(xÀ¢=28, yÀ¢=28)\u001B[0m \u001B[94m0.506 ¬± 0.293\u001B[0m \u001B[37m(2e-03...1e+00)\u001B[0m"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images = math.random_uniform(batch(set=4), spatial(x=28, y=28), channel(channels='red,green,blue'))\n",
    "images.set[-1].channels['red']\n",
    "images[{'set': -1, 'channels': 'red'}]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Further Reading\n",
    "\n",
    "While the dimensionality of neural networks must be specified during network creation, this is not the case for math functions.\n",
    "These [automatically adapt to the number of spatial dimensions of the data that is passed in](N_Dimensional.html).\n",
    "\n",
    "If you want to get deeper into UnifyML, check out the following notebooks:\n",
    "\n",
    "* [Shapes](Shapes.html)\n",
    "* [More on tensors](Tensors.html)\n",
    "* [Data types](Data_Types.html)\n",
    "* [Writing *n*-dimensional code](N_Dimensional.html)\n",
    "\n",
    "[üåê **UnifyML**](https://github.com/holl-/UnifyML)\n",
    "&nbsp; ‚Ä¢ &nbsp; [üìñ **Documentation**](https://holl-.github.io/UnifyML/)\n",
    "&nbsp; ‚Ä¢ &nbsp; [üîó **API**](https://holl-.github.io/UnifyML/unifyml)\n",
    "&nbsp; ‚Ä¢ &nbsp; [**‚ñ∂ Videos**]()\n",
    "&nbsp; ‚Ä¢ &nbsp; [<img src=\"images/colab_logo_small.png\" height=4>](https://colab.research.google.com/github/holl-/UnifyML/blob/main/docs/Examples.ipynb) [**Examples**](https://holl-.github.io/UnifyML/Examples.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}