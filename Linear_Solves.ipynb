{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Linear Solves in UnifyML\n",
    "\n",
    "[![Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/holl-/UnifyML/blob/main/docs/Linear_Solves.ipynb)\n",
    "&nbsp; ‚Ä¢ &nbsp; [üåê **UnifyML**](https://github.com/holl-/UnifyML)\n",
    "&nbsp; ‚Ä¢ &nbsp; [üìñ **Documentation**](https://holl-.github.io/UnifyML/)\n",
    "&nbsp; ‚Ä¢ &nbsp; [üîó **API**](https://holl-.github.io/UnifyML/unifyml)\n",
    "&nbsp; ‚Ä¢ &nbsp; [**‚ñ∂ Videos**]()\n",
    "&nbsp; ‚Ä¢ &nbsp; [<img src=\"images/colab_logo_small.png\" height=4>](https://colab.research.google.com/github/holl-/UnifyML/blob/main/docs/Examples.ipynb) [**Examples**](https://holl-.github.io/UnifyML/Examples.html)\n",
    "\n",
    "Linear solves are a vital part in many simulations and machine learning applications.\n",
    "UnifyML provides an easy-to-use interface for performing linear solves that supports backpropagation via implicit gradients.\n",
    "Dense, sparse, and matrix-free linear systems can be solved this way.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install unifyml"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from unifyml import math\n",
    "from unifyml.math import wrap, channel, dual, Solve, const_vec, tensor"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Linear solves and sparse matrices are supported on all backends.\n",
    "Feel free to choose the below line to use `jax`, `tensorflow` or `numpy` instead."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "torch"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.use('torch')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can perform a linear solve by passing a matrix `A`, right-hand-side vector `b` and initial guess `x0` to [`solve_linear()`](unifyml/math/#unifyml.math.solve_linear).\n",
    "\n",
    "We recommend passing UnifyML tensors. Then, the [dual dimensions of the matrix](Matrices.html#Primal-and-Dual-Dimensions) must match the initial guess and the primal dimensions must match the right-hand-side.\n",
    "\n",
    "Alternatively, `solve_linear()` can be used called with native tensors (see [below](#Linear-Solves-with-Native-Tensors))."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "\u001B[94m(3.000, 2.000)\u001B[0m along \u001B[92mb_vec·∂ú\u001B[0m"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = tensor([[0, 1], [1, 0]], channel('b_vec'), dual('x_vec'))\n",
    "b = tensor([2, 3], channel('b_vec'))\n",
    "x0 = tensor([0, 0], channel('x_vec'))\n",
    "math.solve_linear(A, b, Solve(x0=x0))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "UnifyML implements multiple algorithms to solve linear systems, such as the conjugate gradient method (`CG`) and the stabilized bi-conjugate gradient method (`biCG`).\n",
    "All SciPy solvers are also available.\n",
    "For a full list, see [here](unifyml/math/#unifyml.math.solve_linear)."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "\u001B[94m(3.000, 2.000)\u001B[0m along \u001B[92mb_vec·∂ú\u001B[0m"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.solve_linear(A, b, Solve('CG', x0=x0))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "\u001B[94m(3.000, 2.000)\u001B[0m along \u001B[92mb_vec·∂ú\u001B[0m"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.solve_linear(A, b, Solve('biCG-stab', x0=x0))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "\u001B[94m(3.000, 2.000)\u001B[0m along \u001B[92mb_vec·∂ú\u001B[0m"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.solve_linear(A, b, Solve('scipy-GMres', x0=x0))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Matrix-free Solves\n",
    "\n",
    "Instead of passing a matrix, you can also specify a linear Python function that computes the matrix-vector product.\n",
    "This will typically be slower unless the function is compiled to a matrix."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "\u001B[94m(1.000, 3.000)\u001B[0m along \u001B[92mb_vec·∂ú\u001B[0m"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def linear_function(x):\n",
    "    return x * (2, 1)\n",
    "\n",
    "math.solve_linear(linear_function, b, Solve(x0=x0))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Explicit Matrices from Python Functions\n",
    "\n",
    "UnifyML can also [build an explicit matrix representation](Matrices.html#Building-Matrices-from-Linear-Functions) of the provided Python function.\n",
    "You can do this either by explicitly obtaining the matrix first using [`matrix_from_function`](unifyml/math#unifyml.math.matrix_from_function) or by annotating the linear function with\n",
    "[`jit_compile_linear`](unifyml/math#unifyml.math.jit_compile_linear).\n",
    "If the function adds a constant offset to the output, this will automatically be subtracted from the right-hand-side vector."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\PhD\\UnifyML\\unifyml\\backend\\torch\\_torch_backend.py:752: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\SparseCsrTensorImpl.cpp:56.)\n",
      "  return torch.sparse_csr_tensor(row_pointers, column_indices, values, shape, device=values.device)\n"
     ]
    },
    {
     "data": {
      "text/plain": "\u001B[94m(1.000, 2.000, 1.500, 3.000)\u001B[0m \u001B[92m(b_vec·∂ú=2, x_vec·∂ú=2)\u001B[0m"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from unifyml.math import jit_compile_linear\n",
    "\n",
    "math.solve_linear(jit_compile_linear(linear_function), b, Solve(x0=x0))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Preconditioned Linear Solves\n",
    "\n",
    "UnifyML includes an ILU and experimental cluster preconditioner.\n",
    "To use a preconditioner, simply specify `preconditioner='ilu'` when creating the `Solve` object."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\phiflow2\\lib\\site-packages\\scipy\\sparse\\linalg\\_dsolve\\linsolve.py:590: SparseEfficiencyWarning: CSR matrix format is required. Converting to CSR matrix.\n",
      "  warn('CSR matrix format is required. Converting to CSR matrix.',\n"
     ]
    },
    {
     "data": {
      "text/plain": "\u001B[94m(1.000, 2.000, 1.500, 3.000)\u001B[0m \u001B[92m(b_vec·∂ú=2, x_vec·∂ú=2)\u001B[0m"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.solve_linear(jit_compile_linear(linear_function), b, Solve('scipy-CG', x0=x0, preconditioner='ilu'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The ILU preconditioner always runs on the CPU and should be paired with a SciPy linear solver for optimal efficiency.\n",
    "Available SciPy solvers include `'scipy-direct'`, `'scipy-CG'`, `'scipy-GMres'`, `'scipy-biCG'`, `'scipy-biCG-stab'`, `'scipy-CGS'`, `'scipy-QMR'`, `'scipy-GCrotMK'` (see the [API](unifyml/math/index.html#unifyml.math.solve_linear)).\n",
    "\n",
    "If the matrix or linear function is constant, i.e. only [depends on NumPy arrays](NumPy_Constants.html), the preconditioner computation can be performed during [JIT compilation](JIT.html).\n",
    "\n",
    "[](Matrices.html#Building-Matrices-from-Linear-Functions))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\PhD\\UnifyML\\unifyml\\backend\\torch\\_torch_backend.py:60: TracerWarning: torch.from_numpy results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  tensor = torch.from_numpy(x)\n",
      "C:\\PhD\\UnifyML\\unifyml\\backend\\torch\\_torch_backend.py:752: TracerWarning: torch.sparse_csr_tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  return torch.sparse_csr_tensor(row_pointers, column_indices, values, shape, device=values.device)\n",
      "C:\\PhD\\UnifyML\\unifyml\\backend\\torch\\_torch_backend.py:125: TracerWarning: Converting a tensor to a NumPy array might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  return tensor.cpu().numpy()\n",
      "C:\\PhD\\UnifyML\\unifyml\\backend\\torch\\_torch_backend.py:594: TracerWarning: Converting a tensor to a Python integer might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  return tuple([int(s) for s in tensor.shape])\n",
      "C:\\PhD\\UnifyML\\unifyml\\math\\_tensors.py:699: TracerWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).\n",
      "  return iter(self.native())\n"
     ]
    },
    {
     "data": {
      "text/plain": "\u001B[94m(1.000, 2.000, 1.500, 3.000)\u001B[0m \u001B[92m(b_vec·∂ú=2, x_vec·∂ú=2)\u001B[0m"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@math.jit_compile\n",
    "def jit_perform_solve(b):\n",
    "    return math.solve_linear(jit_compile_linear(linear_function), b, Solve('scipy-CG', x0=x0, preconditioner='ilu'))\n",
    "\n",
    "jit_perform_solve(b)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here, the ILU preconditioner is computed during JIT-compile time since the linear function does not depend on `b`."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Implicit Differentiation\n",
    "\n",
    "UnifyML enables backpropagation through linear solves.\n",
    "Instead of backpropagating through the unrolled loop (which can lead to inaccurate results and cause high memory consumption), Unify runs an ajoint linear solve for the pullback operation."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "\u001B[94m(2.500, 3.750)\u001B[0m along \u001B[92mb_vec·∂ú\u001B[0m"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def loss_function(b):\n",
    "    x = math.solve_linear(jit_compile_linear(linear_function), b, Solve(x0=x0))\n",
    "    return math.l2_loss(x)\n",
    "\n",
    "gradient_function = math.gradient(loss_function, 'b', get_output=False)\n",
    "gradient_function(b)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Matrix Gradients\n",
    "\n",
    "UnifyML can also compute gradients for the (sparse) matrix used in a linear solve, which allows differentiating w.r.t. parameters that influenced the matrix values via backpropagation.\n",
    "To enable this, pass `grad_for_f=True` to the `solve_linear()` call.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "\u001B[94m(1.000, 0.125)\u001B[0m along \u001B[92mx_vec·∂ú\u001B[0m"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@math.jit_compile_linear\n",
    "def conditioned_linear_function(x, conditioning):\n",
    "    return x * conditioning\n",
    "\n",
    "def loss_function(conditioning):\n",
    "    b = math.ones_like(conditioning)\n",
    "    x = math.solve_linear(conditioned_linear_function, b, Solve(x0=x0), conditioning=conditioning, grad_for_f=True)\n",
    "    return math.l2_loss(x)\n",
    "\n",
    "gradient_function = math.gradient(loss_function, 'conditioning', get_output=False)\n",
    "gradient_function(tensor([1., 2.], channel('x_vec')))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Obtaining Additional Information about a Solve\n",
    "\n",
    "All solves are logged internally and can be shown by setting [`unifyml.set_logging_level('debug')`](unifyml#unifyml.set_logging_level).\n",
    "\n",
    "Additional solve properties can be recorded using a [`SolveTape`](unifyml/math#unifyml.math.SolveTape).\n",
    "Recording the full optimization trajectory requires setting `record_trajectories=True`."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "factor_ilu: auto-selecting iterations=1 (eager mode) for matrix \u001B[94m(2.000, 0.000)\u001B[0m; \u001B[94m(0.000, 1.000)\u001B[0m \u001B[92m(vector·∂ú=2, ~vector·µà=2)\u001B[0m (DEBUG), 2023-07-09 17:41:40,829n\n",
      "\n",
      "Running forward pass of custom op forward '_matrix_solve_forward' given args ('y',) containing 1 native tensors (DEBUG), 2023-07-09 17:41:40,839n\n",
      "\n",
      "Performing linear solve scipy-CG with tolerance \u001B[93mfloat64\u001B[0m \u001B[94m1e-05\u001B[0m (rel), \u001B[93mfloat64\u001B[0m \u001B[94m1e-05\u001B[0m (abs), max_iterations=\u001B[94m1000\u001B[0m with backend torch (DEBUG), 2023-07-09 17:41:40,844n\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\phiflow2\\lib\\site-packages\\scipy\\sparse\\linalg\\_dsolve\\linsolve.py:590: SparseEfficiencyWarning: CSR matrix format is required. Converting to CSR matrix.\n",
      "  warn('CSR matrix format is required. Converting to CSR matrix.',\n"
     ]
    }
   ],
   "source": [
    "import unifyml\n",
    "unifyml.set_logging_level('debug')\n",
    "\n",
    "with math.SolveTape() as solves:\n",
    "    math.solve_linear(jit_compile_linear(linear_function), b, Solve('scipy-CG', x0=0 * b, preconditioner='ilu'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The solve information about a performed solve(s) can then be obtained by indexing specific solves by index or `Solve` object."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scipy-CG with tolerance \u001B[93mfloat64\u001B[0m \u001B[94m1e-05\u001B[0m (rel), \u001B[93mfloat64\u001B[0m \u001B[94m1e-05\u001B[0m (abs), max_iterations=\u001B[94m1000\u001B[0m\n",
      "Solution \u001B[94m(1.000, 3.000)\u001B[0m\n",
      "Residual \u001B[94m(0.000, 0.000)\u001B[0m\n",
      "Fun.evals \u001B[94m2\u001B[0m\n",
      "Iterations \u001B[94m1\u001B[0m\n",
      "Diverged \u001B[94mFalse\u001B[0m\n",
      "Converged \u001B[94mTrue\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "print(solves[0].solve)\n",
    "print(\"Solution\", solves[0].x)\n",
    "print(\"Residual\", solves[0].residual)\n",
    "print(\"Fun.evals\", solves[0].function_evaluations)\n",
    "print(\"Iterations\", solves[0].iterations)\n",
    "print(\"Diverged\", solves[0].diverged)\n",
    "print(\"Converged\", solves[0].converged)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Linear Solves with Native Tensors\n",
    "\n",
    "When performing a linear solve without UnifyML tensors, the matrix must have shape (..., N, N) and `x0` and `b` must have shape `(..., N)` where `...` denotes the batch dimensions.\n",
    "This matches the signatures of the native solve functions like `torch.linalg.solve` or `jax.numpy.linalg.solve`."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running forward pass of custom op forward '_matrix_solve_forward' given args ('y', 'matrix') containing 2 native tensors (DEBUG), 2023-07-09 17:41:08,054n\n",
      "\n",
      "Performing linear solve auto with tolerance \u001B[93mfloat64\u001B[0m \u001B[94m1e-05\u001B[0m (rel), \u001B[93mfloat64\u001B[0m \u001B[94m1e-05\u001B[0m (abs), max_iterations=\u001B[94m1000\u001B[0m with backend torch (DEBUG), 2023-07-09 17:41:08,058n\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "tensor([3., 2.], device='cuda:0')"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "A = torch.tensor([[0., 1], [1, 0]])\n",
    "b = torch.tensor([2., 3])\n",
    "x0 = torch.tensor([0., 0])\n",
    "math.solve_linear(A, b, Solve(x0=x0))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Further Reading\n",
    "\n",
    "We will upload a whitepaper to the ArXiv shortly, describing the implemented algorithms.\n",
    "\n",
    "&nbsp; ‚Ä¢ &nbsp; [üåê **UnifyML**](https://github.com/holl-/UnifyML)\n",
    "&nbsp; ‚Ä¢ &nbsp; [üìñ **Documentation**](https://holl-.github.io/UnifyML/)\n",
    "&nbsp; ‚Ä¢ &nbsp; [üîó **API**](https://holl-.github.io/UnifyML/unifyml)\n",
    "&nbsp; ‚Ä¢ &nbsp; [**‚ñ∂ Videos**]()\n",
    "&nbsp; ‚Ä¢ &nbsp; [<img src=\"images/colab_logo_small.png\" height=4>](https://colab.research.google.com/github/holl-/UnifyML/blob/main/docs/Examples.ipynb) [**Examples**](https://holl-.github.io/UnifyML/Examples.html)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}