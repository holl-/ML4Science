{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Device Handling in UnifyML\n",
    "\n",
    "[![Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/holl-/UnifyML/blob/main/docs/Devices.ipynb)\n",
    "&nbsp; ‚Ä¢ &nbsp; [üåê **UnifyML**](https://github.com/holl-/UnifyML)\n",
    "&nbsp; ‚Ä¢ &nbsp; [üìñ **Documentation**](https://holl-.github.io/UnifyML/)\n",
    "&nbsp; ‚Ä¢ &nbsp; [üîó **API**](https://holl-.github.io/UnifyML/unifyml)\n",
    "&nbsp; ‚Ä¢ &nbsp; [**‚ñ∂ Videos**]()\n",
    "&nbsp; ‚Ä¢ &nbsp; [<img src=\"images/colab_logo_small.png\" height=4>](https://colab.research.google.com/github/holl-/UnifyML/blob/main/docs/Examples.ipynb) [**Examples**](https://holl-.github.io/UnifyML/Examples.html)\n",
    "\n",
    "This notebook is work in progress. It will explain\n",
    "\n",
    "* Selecting a device CPU / GPU\n",
    "* `to_device()`"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install unifyml\n",
    "\n",
    "from unifyml import math, backend"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Compute Devices\n",
    "\n",
    "UnifyML abstracts [`ComputeDevices`](unifyml/backend/#unifyml.backend.ComputeDevice), such as CPUs, GPUs and TPUs.\n",
    "You can obtain a list of available devices using [`Backend.list_devices()`](unifyml/backend/#unifyml.backend.Backend.list_devices)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "[torch device 'CPU' (CPU 'cpu') | 31965 MB | 8 processors | ]"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BACKEND = math.use('torch')\n",
    "BACKEND.list_devices('CPU')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Compute devices are bound to the computing library that uses it, i.e. the CPU returned by PyTorch is not the same object as the CPU returned by NumPy."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "[numpy device 'CPU' (CPU 'CPU') | 31965 MB | 8 processors | ]"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from unifyml.backend import NUMPY\n",
    "NUMPY.list_devices('CPU')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Setting the Default Device\n",
    "\n",
    "We can set the default device per backend by reference or type."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BACKEND.set_default_device(BACKEND.list_devices()[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/holl/PycharmProjects/UnifyML/unifyml/backend/_backend.py:245: RuntimeWarning: torch: Cannot select 'GPU' because no device of this type is available.\n",
      "  warnings.warn(f\"{self.name}: Cannot select '{device}' because no device of this type is available.\", RuntimeWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": "False"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BACKEND.set_default_device('GPU')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Tensors created by that backend will be allocated on that device from now on.\n",
    "Already allocated tensors are left untouched.\n",
    "\n",
    "Combining tensors allocated on different devices may lead to errors!"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Moving Tensors to a Different Device\n",
    "\n",
    "You can move any tensor to a different compute device"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "torch device 'CPU' (CPU 'cpu') | 31965 MB | 8 processors | "
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = math.zeros()\n",
    "tensor.device"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "\u001B[94m0.0\u001B[0m"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.to_device(tensor, 'CPU')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "[`math.to_device()`](unifyml/math#unifyml.math.to_device) also supports pytrees and data classes that contain tensors."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Further Reading\n",
    "\n",
    "UnifyML also supports [moving tensors to different backend libraries](Convert.html) without copying them.\n",
    "\n",
    "[üåê **UnifyML**](https://github.com/holl-/UnifyML)\n",
    "&nbsp; ‚Ä¢ &nbsp; [üìñ **Documentation**](https://holl-.github.io/UnifyML/unifyml/)\n",
    "&nbsp; ‚Ä¢ &nbsp; [üîó **API**](https://holl-.github.io/UnifyML/unifyml)\n",
    "&nbsp; ‚Ä¢ &nbsp; [**‚ñ∂ Videos**]()\n",
    "&nbsp; ‚Ä¢ &nbsp; [<img src=\"images/colab_logo_small.png\" height=4>](https://colab.research.google.com/github/holl-/UnifyML/blob/main/docs/Examples.ipynb) [**Examples**](https://holl-.github.io/UnifyML/Examples.html)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}